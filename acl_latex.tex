% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[review]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

% \title{Instructions for *ACL Proceedings}

\title{Chinchunmei at SemEval-2025 Task 11: Boosting the Emotion Perception Ability of Large Language Models using Contrastive Concept}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{First Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  \texttt{email@domain} \\\And
  Second Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  \texttt{email@domain} \\}

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
\begin{abstract}
This document is a supplement to the general instructions for *ACL authors. It contains instructions for using the \LaTeX{} style files for ACL conferences.
The document itself conforms to its own specifications, and is therefore an example of what your manuscript should look like.
These instructions should be used both for papers submitted for review and for final versions of accepted papers.
\end{abstract}

\section{Introduction}
\iffalse
These instructions are for authors submitting papers to *ACL conferences using \LaTeX. They are not self-contained. All authors must follow the general instructions for *ACL proceedings,\footnote{\url{http://acl-org.github.io/ACLPUB/formatting.html}} and this document contains additional instructions for the \LaTeX{} style files.

The templates include the \LaTeX{} source of this document (\texttt{acl\_latex.tex}),
the \LaTeX{} style file used to format it (\texttt{acl.sty}),
an ACL bibliography style (\texttt{acl\_natbib.bst}),
an example bibliography (\texttt{custom.bib}),
and the bibliography for the ACL Anthology (\texttt{anthology.bib}).
\fi

% Text-based Emotion Detection(TBED)一直都是NLP研究中的一个热点。其已被广泛应用于社交媒体分析，心理疾病治疗，用户喜好预测，以及对话系统。基于对Emotion的定义的差异，TBED可简单分为两类做法：(1).若情绪被划分为不同的类别，则情绪识别则主要采用分类算法，通过模型预测文本是否包含对应的情绪 (2). 若情绪被定义为为相互关联的实体且每个实体存在强度差异，则情绪识别大多采用回归算法，通过预测文本在多个情绪维度上的强度来达成目标。同时，由于情绪表达非常敏感且复杂，情绪识别还面临以下挑战：1. 不同情绪的差异往往非常细微，且情绪的表达也往往通过隐形的方式(比喻，或引发情绪的情况)表达出来。 2. 不同的文化背景与语言也会影响情绪的判断。这些挑战暗示了情绪识别不能仅依赖特定字典进行判断，而是需要结合文化，语种，背景知识，与更加先进的语义理解来给出综合判断。

Text-Based Emotion Detection (TBED) has long been a prominent research area in NLP, with widespread applications in social media analysis \cite{kuamri2017real, salam2018emotion, cassab2020ontology}, mental health treatment \cite{kusal2021ai, krommyda2021experimental}, and dialogue systems \cite{liu2022dialogueein,ide2022building,hu2021dialoguecrn}. Depending on how emotions are defined, TBED can be broadly categorized into two approaches: (1). Classification-based methods, where emotions are categorized into discrete labels \cite{ekman1969repertoire,plutchik1982psycho}. (2). Scoring-based methods, where emotions are treated as interrelated entities with varying intensity levels \cite{russell1977evidence}. 

However, due to the nuanced and complex nature of emotional expression, TBED faces several key challenges \cite{al2024challenges}: (1). The distinction between different emotions is often subtle, and emotions are often conveyed implicitly—through metaphors or situational cues rather than explicit words. (2). Cultural and linguistic differences influence emotion perception. These challenges make TBED difficult to rely solely on predefined lexicons. A robust TBED system must integrate cultural context, linguistic diversity, background knowledge, and advanced semantic understanding.

% 本次SemEVAL 2025，主办方在TASK11 上提出了 “[**Bridging the Gap in Text-Based Emotion Detection**](https://github.com/emotion-analysis-project/SemEval2025-task11)” 挑战比赛。其比赛数据集包含多达33个不同的语言，且放出了类别标签和强度标签作为赛题A和赛题B。其需识别的情感为“给定一句话读者认为说话者可能感受到什么样的情绪”，而非读者的情感或语句中提到的其他人的情感。其情感类别定义采用了 Ekman’s的框架(Ekman and Friesen, 1981)，包含六个基础情感分类: anger,fear, sadness, joy, disgust and surprise。同时其在赛题B的强度预测上，为每个情感设立了4个强度level。其赛题设计既覆盖了现有两大TBED做法，也包含了多语言与细微差异识别的挑战。

For SemEval-2025, Task 11, titled Bridging the Gap in Text-Based Emotion Detection, introduces a multilingual benchmark covering 28 languages. The competition consists of task A (classification) and task B (intensity prediction). The goal is to identify the speaker's perceived emotion in a given sentence. Emotion categories follow Ekman's framework\cite{ekman1969repertoire}, encompassing six basic emotions: anger, fear, sadness, joy, disgust, and surprise. Task B further introduces four intensity levels for each emotion. This competition setup encapsulates both primary TBED methodologies while incorporating challenges in multilingual and fine-grained emotion recognition. 

% 为了兼顾赛题A与赛题B两个任务，同时支持对多达33种语言的情感预测，我们放弃了传统的Encoder分类框架，转而使用了生成式大语言模型。通过监督学习，可以让模型直接生成预测标签，并且不同track 可以使用不同的prompt 模版统一到一个模型中。同时，得益于其预训练预料的规模与语种覆盖率，使用大语言模型也能为多语种情感识别提供良好的支持。

To address both tracks while supporting emotion prediction across 28 languages, we give up the traditional encoder-based classification frameworks and adopt the generative large language model (LLM). This decision is driven by its robust multi-task integration capabilities and strong support for cross-linguistic applications.

\iffalse
% 在本次比赛，我们首先设计了标准预测任务，通过训练让LLM直接预测每条样本的emotion label与level。同时，为了强化大语言模型对文本上细微的情感表达差异的识别能力，我们受Chinchunmei的启发引入并改良了Contrastive Reasoning Calibration技术。其原理是通过样本比较的方式，让模型矫正目标样本的打分。同时为了进一步强化大模型对于情感标签预测的准确性，我们引入了Self refinement 流程。通过让大模型判断并修改已有预测，我们能进一步提升部分标签的准确性与鲁棒性。

We first designed a standard prediction task (ST), training the LLM to predict each sample's emotion label and intensity level directly. Meanwhile, to enhance the model's ability to distinguish nuanced emotional traits in text, we employ Contrastive Reasoning Calibration (CRC) \cite{li2024chinchunmei} techniques and refine it to suit this competition. This method allows the model to adjust its predictions through direct sample comparisons. Additionally, to further improve the prediction accuracy, we introduced a Self-refinement process, enabling the model to review and refine its outputs. 

% 我们的核心贡献如下

% 1. 我们将前序CRC技术从1V1 对比拓展到了1V3对比 (CRC4)。通过在一次比较中引入更多的样本，使得模型输出更加鲁棒。
% 2. 为了强化模型对于标签的认知，我们引入了纠错任务训练。同时，我们复用了纠错任务模版作为self refinement。其可被用在对标准预测，CRC预测以及CRC4预测进行纠错，从而在部分标签上取得更好的效果。
% 3. 为了缓解英语任务的样本稀少问题，我们融合了多个任务到一个模型中并探索了不同融合方式对于最终预测结果的收益。同时我们也在有限的计算资源下探索了英语与其他语种文本对于各自语种的情感识别的贡献。
% 4. 基于贡献三中不同的方案在不同语种不同标签上的效果，我们选取了每个标签所对应的最优方案作为我们的提交方案。在最后的比赛排名上，track A与track B的英语语种上我们分别拿到了12/91 和7/42 的成绩。同时在trackA上我们的方案在AMH语种上拿到了第一，16个语种排名前10.在track B上我们的方案在所有的语种排名均在前10.

Our contributions are as follows:
\begin{itemize}
	\item We extended the previous CRC technique from 1V1 comparison to 1V3 comparison (CRC4). Incorporating more samples in each comparison enhanced the model's robustness and discriminative ability.
	\item We introduced an error correction training task to improve the model's understanding of emotion labels. We repurposed the error correction template for Self-refinement, enabling it to refine predictions across ST, CRC, and CRC4 outputs, improving accuracy for certain labels.
	\item Based on the performance of different task fusion strategies across languages and labels, we selected the optimal approach for each label as our final submission. In the leaderboard, our approach achieved Track A top 10 in 16 languages and 12th in English; Track B top 10 across all languages and 7th in English.
\end{itemize}
\fi

% 由于情感表达的复杂性和情感标签的不确定性，我们决定采用两套备选方案：基于样本的对比方案和基于生成结果的对比方案。基于样本的对比方案采用CRC技术。其原理是通过样本比较的方式，让模型生成多条更加可靠的的预测并进行投票表决。基于生成结果的对比方案采用偏好优化技术，通过增加正确输出的对数概率并减少错误输出的对数概率，优化模型对于标签的理解能力。受限于计算资源限制，我们探索了DPO与Orpo这两个无需reward model的方案。

Due to the complexity of emotional expression and the ambiguity of sentiment labels, we adopted two alternative approaches: a sample-based contrastive scheme and a generation-based contrastive scheme. The sample-based approach leverages Contrastive Reasoning Calibration technology (CRC) \cite{li2024chinchunmei}, which enhances prediction reliability by generating multiple predictions through sample comparisons and aggregating them via majority voting. The generation-based contrastive scheme employs preference optimization techniques \cite{rafailov2023direct, hong2024orpo, meng2025simpo}, refining the model’s comprehension of sentiment labels by increasing the log probability of correct outputs while reducing that of incorrect ones. Given computational constraints, we explored DPO \cite{rafailov2023direct}, SimPO\cite{meng2025simpo},  ORPO \cite{rafailov2023direct}, three methods that eliminate the need for a reward model.

% 我们的核心贡献如下

% 1. 我们在有限的计算资源中探索了非英语数据对于英语预测的贡献。令人意外的是，试验结果显示非英语数据的引入会损害英语情感预测的效果，不论是分类任务（track a)还是打分任务(track b).
% 2. 我们详细探索了两种对比方案在该数据集上的效果。在样本对比方案类别上，CRC技术对于该数据集只有负收益。在偏好优化上，也只有DPO在track b上展现了明显的正向收益。SimPO与Orpo不仅会带来效果下降，甚至会让模型丧失规范输出的能力，从而影响结果提取。
% 3. 在最后的比赛排名上，track A与track B的英语语种上我们分别拿到了12/91 和7/42 的成绩。同时在trackA上我们的方案在AMH语种上拿到了第一，16个语种排名前10.在track B上我们的方案在所有的语种排名均在前10.

Our key contributions are as follows:

\begin{itemize}
	\item We explored the impact of non-English data on English sentiment prediction under limited computational resources. Surprisingly, experimental results indicate that incorporating non-English data degrades performance in both classification tasks (Track A) and scoring tasks (Track B).
	\item We conducted an in-depth evaluation of two contrastive approaches on this dataset. In the sample-based contrastive category, CRC technology yielded only negative returns. For preference optimization, DPO demonstrated a significant positive effect on Track B, whereas SimPO and ORPO not only led to performance degradation but also impaired the model's ability to produce well-structured outputs, compromising result extraction.
	\item In the leaderboard, our approach achieved Track A top 10 in 16 languages and 12th in English; Track B top 10 across all languages and 7th in English.
\end{itemize}

\section{Methodology}

% 得益于生成式模型的统一预测范式，我们能轻易整合不同赛题不同任务到一个模型中，通过在推理式采用不同的prompt来指定模型需执行的赛题或任务。我们首先为两个赛题设计了不同的标准预测模版，让模型直接输出所有标签的预测结果。其次，针对样本对比方案，我们使用了Contrastive Reasoning Calibration方案，让模型在某个标签上先对比两条样本的预测情况，再给出各个样本的实际预测结果。针对生成结果的对比方案，我们使用了DPO，SimPO与Orpo，通过构建生成的正反例强化模型对于预测的敏感程度。

Leveraging the unified prediction paradigm of generative models, we seamlessly integrate both competition tracks and different subtasks into a single model. By employing task-specific prompts during inference, we directe the model to perform the required prediction subtask accordingly. 

First, we design standard prediction templates (ST) for the two tracks, enabling the model to output all label predictions directly. Second, for the sample-based contrastive approach, we adopt the Contrastive Reasoning Calibration (CRC) method, where the model first compares the predictions of two samples for a given label before generating the final predictions for each sample. Lastly, for the generation-based contrastive approach, we compare DPO, SimPO, and ORPO, enhancing the model’s sensitivity to prediction correctness by constructing positive and negative examples during training.

\subsection{Standard Prediction}

% 标准任务为利用大语言模型直接进行预测。我们将文本内容整合到预先设计好的prompt模版中作为输入，并将标签结果format成自然语言作为输出的ground truth。通过对格式化好的输入与ground truth进行监督微调得到标准预测的模型。在推理时采用同样的prompt模版整合代推理文字作为输入，通过解析输出的自然语言，拿到各个标签对应的结果。其模版如Appendix 1所示
The standard prediction task (ST) involves direct prediction using a large language model. We integrate the text content into a pre-designed prompt template as input and format the label results as the ground truth output. The model is then fine-tuned through supervised learning (SFT) using this formatted input and corresponding output.

During inference, we apply the same prompt template to incorporate the input text for prediction. By parsing the generated output, we extract the corresponding label predictions. The template details can be found in Appendix 1.

\subsection{Contrastive Reasoning Calibration}
% CRC任务为样本对比任务。通过训练模型对比两条样本在打分上的异同，从而强化模型对于情感表达细微差异的识别能力。其分为训练和预测两个部分。
The CRC task is a sample-based contrastive learning approach designed to enhance the model’s ability to discern subtle differences in sentiment expression. By comparing the scoring variations between two samples, model generated calibrated prediction. This process consists of training and inference phases.

% 在训练中，我们随机从训练集中抽取两条样本，基于Appendix 2所示的模版构成对比组输入。其目标生成包含两个部分：对比结论与各自预测结果。其对比结论为一段自然语言，总结了两条样本在某个标签上的高低/强弱情况。其预测结果为每个样本在某一标签上的具体打分。其输出模版如Appendix3 所示。

During training, we randomly select two samples from the training set and construct a contrastive input using the template in Appendix 2. The target output comprises two components: a contrastive summary and predictions. The contrastive summary, expressed in natural language, highlights the  existence or intensity of a specific label between the two samples. The predictions provide explicit scores for each sample on the given label. The format of the output is shown in Appendix 3.

% 由于两两随机采样能生成巨量的训练样本，因此我们为track a和track b分别设置了一个样本总数上线。对于track a，每个标签采样3000条对比样本。对于track b，每个标签采样6000条对比样本。这是因为相比于track a ，track b的预测打分多于track a。

Given that random pairwise sampling can generate a vast amount of training data, we imposed an upper limit on the total number of sampled pairs for each track. Specifically, for Track A, we sampled 3,000 contrastive pairs per label, while for Track B, we sampled 6,000 pairs per label, as Track B involves more fine-grained scoring compared to Track A.

% 在推理时，每条待预测的样本将同随机抽取的训练样本构建对比组。由于模型对于训练样本预测极为准确，因此我们希望其可作为预测的对比量纲，从而削减预测的不确定性。两条样本被整合到Appendix 2 所示的模版中作为输入，待预测的样本将会被随机放置在位置1或位置2.重复上述过程N次获得N条输入，并由模型生成N条预测结果。最终通过投票机制，将得票最高的打分作为最终输出。

During inference, each test sample is paired with a randomly selected training sample to form a contrastive group. Since the model achieves highly accurate predictions on training samples, these samples serve as reliable reference points, reducing prediction uncertainty. The two samples are integrated into the prompt template (Appendix 2), with the test sample randomly assigned to either position 1 or position 2. This process is repeated $N$ times to generate $N$ different input instances, producing $N$ predictions. The final score is determined through a voting mechanism, where the most frequently predicted score is selected as the final output.

\subsection{Preference Optimization}

% 为了强化模型对于打分的敏感性，我们还引入了perference optimiztion。 但是，受限于计算资源，我们仅试验了无需reward model的技术方案。其中包括DPO， SimPO， 以及Orpo

To enhance the model’s sensitivity to scoring, we incorporate preference optimization. However, due to computational constraints, we only explore techniques that do not require a reward model, including DPO, SimPO, and ORPO.

% Direct Preference Optimization (DPO)通过**相对概率比**来优化语言模型，使其更倾向于偏好回答。(EQ1)。 pai_theta与pai_ref分别指代待优化的模型和初始模型。y_w和y_l分别指代正确的输出和错误的输出。Beta为缩放超参数。该优化流程被用在SFT之后

DPO optimizes the language model by maximizing the relative probability ratio to favor preferred outputs (EQ1). Here, $\pi_{\theta}$ and $\pi_{ref}$ represent the target and reference models, respectively, while $y_w$ and $y_l$ denote the correct and incorrect outputs. $\beta$ is a scaling hyperparameter. This optimization process is applied after SFT.

% SimPO采用类似的优化目标（EQ2）。通过直接优化目标模型的输出概率，SimPO使模型更偏向于偏好答案。然而其简化了DPO，丢弃了参考模型，并且使用生成长度约束loss。该优化流程被用在SFT之后。

SimPO adopts a similar optimization objective (EQ2), directly enhancing the probability of the target model’s preferred outputs. However, it simplifies DPO by discarding the reference model and using a length-constrained loss. Like DPO, SimPO is also applied after SFT.

% Orpo则是对将对比的思路放到了SFT阶段(EQ3)。通过在SFT loss上新增正负例的对比term，使得高奖励的回答在训练过程中获得更高的学习权重。该流程会直接替换SFT流程。

ORPO integrates the contrastive approach directly into the SFT phase (EQ3). By adding contrastive terms for $y_w$ and $y_l$ in the SFT loss function, ORPO ensures that highly rewarded responses receive greater weight during training. This process replaces the standard SFT procedure.

% 在训练样本准备时，为了强化模型对标签打分的敏感程度，我们仅mute 标签打分作为y_l。针对标准预测任务，mute 一个，两个，三个，四个，五个标签的概率为[63.8%, 26.1%, 8.3%, 1.6%, 0.1%]。针对CRC任务，mute 一条与两条样本的打分的概率为[90%, 10%]. 当mutation触发时，随机从标签剩余取值中取一个作为错误打分。

In preparing training samples, to refine the model’s sensitivity to label scores, we muted label scores as $y_l$. For the standard prediction task, the probabilities of muting one, two, three, four, or five labels are [63.8\%, 26.1\%, 8.3\%, 1.6\%, 0.1\%], respectively. For the CRC task, the probabilities of muting one or two sample scores are [90\%, 10\%]. When mutation occurs, a random incorrect score is chosen from the remaining label values.



\section{Engines}

To produce a PDF file, pdf\LaTeX{} is strongly recommended (over original \LaTeX{} plus dvips+ps2pdf or dvipdf).
The style file \texttt{acl.sty} can also be used with
lua\LaTeX{} and
Xe\LaTeX{}, which are especially suitable for text in non-Latin scripts.
The file \texttt{acl\_lualatex.tex} in this repository provides
an example of how to use \texttt{acl.sty} with either
lua\LaTeX{} or
Xe\LaTeX{}.

\section{Preamble}

The first line of the file must be
\begin{quote}
\begin{verbatim}
\documentclass[11pt]{article}
\end{verbatim}
\end{quote}

To load the style file in the review version:
\begin{quote}
\begin{verbatim}
\usepackage[review]{acl}
\end{verbatim}
\end{quote}
For the final version, omit the \verb|review| option:
\begin{quote}
\begin{verbatim}
\usepackage{acl}
\end{verbatim}
\end{quote}

To use Times Roman, put the following in the preamble:
\begin{quote}
\begin{verbatim}
\usepackage{times}
\end{verbatim}
\end{quote}
(Alternatives like txfonts or newtx are also acceptable.)

Please see the \LaTeX{} source of this document for comments on other packages that may be useful.

Set the title and author using \verb|\title| and \verb|\author|. Within the author list, format multiple authors using \verb|\and| and \verb|\And| and \verb|\AND|; please see the \LaTeX{} source for examples.

By default, the box containing the title and author names is set to the minimum of 5 cm. If you need more space, include the following in the preamble:
\begin{quote}
\begin{verbatim}
\setlength\titlebox{<dim>}
\end{verbatim}
\end{quote}
where \verb|<dim>| is replaced with a length. Do not set this length smaller than 5 cm.

\section{Document Body}

\subsection{Footnotes}

Footnotes are inserted with the \verb|\footnote| command.\footnote{This is a footnote.}

\subsection{Tables and figures}

See Table~\ref{tab:accents} for an example of a table and its caption.
\textbf{Do not override the default caption sizes.}

\begin{table}
  \centering
  \begin{tabular}{lc}
    \hline
    \textbf{Command} & \textbf{Output} \\
    \hline
    \verb|{\"a}|     & {\"a}           \\
    \verb|{\^e}|     & {\^e}           \\
    \verb|{\`i}|     & {\`i}           \\
    \verb|{\.I}|     & {\.I}           \\
    \verb|{\o}|      & {\o}            \\
    \verb|{\'u}|     & {\'u}           \\
    \verb|{\aa}|     & {\aa}           \\\hline
  \end{tabular}
  \begin{tabular}{lc}
    \hline
    \textbf{Command} & \textbf{Output} \\
    \hline
    \verb|{\c c}|    & {\c c}          \\
    \verb|{\u g}|    & {\u g}          \\
    \verb|{\l}|      & {\l}            \\
    \verb|{\~n}|     & {\~n}           \\
    \verb|{\H o}|    & {\H o}          \\
    \verb|{\v r}|    & {\v r}          \\
    \verb|{\ss}|     & {\ss}           \\
    \hline
  \end{tabular}
  \caption{Example commands for accented characters, to be used in, \emph{e.g.}, Bib\TeX{} entries.}
  \label{tab:accents}
\end{table}

As much as possible, fonts in figures should conform
to the document fonts. See Figure~\ref{fig:experiments} for an example of a figure and its caption.

Using the \verb|graphicx| package graphics files can be included within figure
environment at an appropriate point within the text.
The \verb|graphicx| package supports various optional arguments to control the
appearance of the figure.
You must include it explicitly in the \LaTeX{} preamble (after the
\verb|\documentclass| declaration and before \verb|\begin{document}|) using
\verb|\usepackage{graphicx}|.

\begin{figure}[t]
  \includegraphics[width=\columnwidth]{example-image-golden}
  \caption{A figure with a caption that runs for more than one line.
    Example image is usually available through the \texttt{mwe} package
    without even mentioning it in the preamble.}
  \label{fig:experiments}
\end{figure}

\begin{figure*}[t]
  \includegraphics[width=0.48\linewidth]{example-image-a} \hfill
  \includegraphics[width=0.48\linewidth]{example-image-b}
  \caption {A minimal working example to demonstrate how to place
    two images side-by-side.}
\end{figure*}

\subsection{Hyperlinks}

Users of older versions of \LaTeX{} may encounter the following error during compilation:
\begin{quote}
\verb|\pdfendlink| ended up in different nesting level than \verb|\pdfstartlink|.
\end{quote}
This happens when pdf\LaTeX{} is used and a citation splits across a page boundary. The best way to fix this is to upgrade \LaTeX{} to 2018-12-01 or later.

\subsection{Citations}

\begin{table*}
  \centering
  \begin{tabular}{lll}
    \hline
    \textbf{Output}           & \textbf{natbib command} & \textbf{ACL only command} \\
    \hline
    \citep{Gusfield:97}       & \verb|\citep|           &                           \\
    \citealp{Gusfield:97}     & \verb|\citealp|         &                           \\
    \citet{Gusfield:97}       & \verb|\citet|           &                           \\
    \citeyearpar{Gusfield:97} & \verb|\citeyearpar|     &                           \\
    \citeposs{Gusfield:97}    &                         & \verb|\citeposs|          \\
    \hline
  \end{tabular}
  \caption{\label{citation-guide}
    Citation commands supported by the style file.
    The style is based on the natbib package and supports all natbib citation commands.
    It also supports commands defined in previous ACL style files for compatibility.
  }
\end{table*}

Table~\ref{citation-guide} shows the syntax supported by the style files.
We encourage you to use the natbib styles.
You can use the command \verb|\citet| (cite in text) to get ``author (year)'' citations, like this citation to a paper by \citet{Gusfield:97}.
You can use the command \verb|\citep| (cite in parentheses) to get ``(author, year)'' citations \citep{Gusfield:97}.
You can use the command \verb|\citealp| (alternative cite without parentheses) to get ``author, year'' citations, which is useful for using citations within parentheses (e.g. \citealp{Gusfield:97}).

A possessive citation can be made with the command \verb|\citeposs|.
This is not a standard natbib command, so it is generally not compatible
with other style files.

\subsection{References}

\nocite{Ando2005,andrew2007scalable,rasooli-tetrault-2015}

The \LaTeX{} and Bib\TeX{} style files provided roughly follow the American Psychological Association format.
If your own bib file is named \texttt{custom.bib}, then placing the following before any appendices in your \LaTeX{} file will generate the references section for you:
\begin{quote}
\begin{verbatim}
\bibliography{custom}
\end{verbatim}
\end{quote}

You can obtain the complete ACL Anthology as a Bib\TeX{} file from \url{https://aclweb.org/anthology/anthology.bib.gz}.
To include both the Anthology and your own .bib file, use the following instead of the above.
\begin{quote}
\begin{verbatim}
\bibliography{anthology,custom}
\end{verbatim}
\end{quote}

Please see Section~\ref{sec:bibtex} for information on preparing Bib\TeX{} files.

\subsection{Equations}

An example equation is shown below:
\begin{equation}
  \label{eq:example}
  A = \pi r^2
\end{equation}

Labels for equation numbers, sections, subsections, figures and tables
are all defined with the \verb|\label{label}| command and cross references
to them are made with the \verb|\ref{label}| command.

This an example cross-reference to Equation~\ref{eq:example}.

\subsection{Appendices}

Use \verb|\appendix| before any appendix section to switch the section numbering over to letters. See Appendix~\ref{sec:appendix} for an example.

\section{Bib\TeX{} Files}
\label{sec:bibtex}

Unicode cannot be used in Bib\TeX{} entries, and some ways of typing special characters can disrupt Bib\TeX's alphabetization. The recommended way of typing special characters is shown in Table~\ref{tab:accents}.

Please ensure that Bib\TeX{} records contain DOIs or URLs when possible, and for all the ACL materials that you reference.
Use the \verb|doi| field for DOIs and the \verb|url| field for URLs.
If a Bib\TeX{} entry has a URL or DOI field, the paper title in the references section will appear as a hyperlink to the paper, using the hyperref \LaTeX{} package.

\section*{Limitations}

Since December 2023, a "Limitations" section has been required for all papers submitted to ACL Rolling Review (ARR). This section should be placed at the end of the paper, before the references. The "Limitations" section (along with, optionally, a section for ethical considerations) may be up to one page and will not count toward the final page limit. Note that these files may be used by venues that do not rely on ARR so it is recommended to verify the requirement of a "Limitations" section and other criteria with the venue in question.

\section*{Acknowledgments}

This document has been adapted
by Steven Bethard, Ryan Cotterell and Rui Yan
from the instructions for earlier ACL and NAACL proceedings, including those for
ACL 2019 by Douwe Kiela and Ivan Vuli\'{c},
NAACL 2019 by Stephanie Lukin and Alla Roskovskaya,
ACL 2018 by Shay Cohen, Kevin Gimpel, and Wei Lu,
NAACL 2018 by Margaret Mitchell and Stephanie Lukin,
Bib\TeX{} suggestions for (NA)ACL 2017/2018 from Jason Eisner,
ACL 2017 by Dan Gildea and Min-Yen Kan,
NAACL 2017 by Margaret Mitchell,
ACL 2012 by Maggie Li and Michael White,
ACL 2010 by Jing-Shin Chang and Philipp Koehn,
ACL 2008 by Johanna D. Moore, Simone Teufel, James Allan, and Sadaoki Furui,
ACL 2005 by Hwee Tou Ng and Kemal Oflazer,
ACL 2002 by Eugene Charniak and Dekang Lin,
and earlier ACL and EACL formats written by several people, including
John Chen, Henry S. Thompson and Donald Walker.
Additional elements were taken from the formatting instructions of the \emph{International Joint Conference on Artificial Intelligence} and the \emph{Conference on Computer Vision and Pattern Recognition}.

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{custom}

\appendix

\section{Example Appendix}
\label{sec:appendix}

This is an appendix.

\end{document}
